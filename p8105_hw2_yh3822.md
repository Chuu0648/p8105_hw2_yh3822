p8105_hw2_yh3822
================
2024-10-01

``` r
library(tidyverse)
library(readxl)
library(dplyr)
```

## Problem 1

``` r
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%
  mutate(entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE))
```

This dataset describes the information related to each entrance and exit
for each subway station in NYC, and it contains 19 variables, which are
line, station_name, station_latitude, station_longitude, route1, route2,
route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, vending, entrance_type, and ada. To clean up the data, I
first made all the variable names lowercase, then filtered from there
the variables I needed to use, removed the unnecessary ones, and finally
converted the character variable “entry” to a logical variable. The
dimension of this dataset is 1868 rows \* 19 columns. I think these data
are tidy.

``` r
distinct_stations = nyc_transit_df %>%
  distinct(station_name, line)
```

There are 465 distinct stations.

``` r
ada_stations = nyc_transit_df %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line)
```

There are 84 stations are ADA compliant.

``` r
no_vending_entry = nyc_transit_df %>%
  filter(vending == "NO" & entry == TRUE) %>%
  distinct(station_name, line)
```

There are 9.2473118 percent of station entrances / exits without vending
allow entrance.

``` r
nyc_transit_df = nyc_transit_df %>%
  mutate(across(starts_with("route"), as.character))

nyc_transit_df_tidy = nyc_transit_df %>%
  pivot_longer(cols = starts_with("route"),
               names_to = "route_number",   
               values_to = "route_name",    
               values_drop_na = TRUE)
```

``` r
a_train_stations = nyc_transit_df_tidy %>%
  filter(route_name == "A") %>%
  distinct(station_name, line)
```

There are 60 distinct stations that served A train.

``` r
ada_a_train_stations = nyc_transit_df_tidy %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(station_name, line)
```

There are 17 distinct stations that served A train are ADA compliant.

## Problem 2

``` r
mr_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered, -x15, -x16) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(sports_balls = as.integer(round(sports_balls, 0))) %>%
  mutate(trash_wheel = "Mr. Trash Wheel") %>%
  mutate(year = as.integer(year))
```

``` r
professor_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(trash_wheel = "Professor Trash Wheel") %>%
  mutate(year = as.integer(year))
```

``` r
gwynnda_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(trash_wheel = "Gwynnda Trash Wheel") %>%
  mutate(year = as.integer(year))
```

``` r
combined_trash_wheel_data <- bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df)
```

This dataset contains information on the various types of trash for the
three trash wheels, which are Mr. Trash Wheel, Professor Trash Wheel,
and Gwynnda Trash Wheel, , reflecting the efforts of these devices to
clean up waterways. The dataset contains 845 observations, with key
variables including dumpster_number, month, year, weight_tons,
plastic_bottles, polystyrene_containers, and so on. The total weight of
trash collected by Professor Trash Wheel is 216.26 tons. Additionally,
Gwynnda collected 1.812^{4} cigarette butts in June 2022.

## Problem 3

First, import and clean the data.

I found that only the name in the bakers dataset contains both the first
and last name, the other two only have the first name, so I turned the
name in the bakers dataset into two variables, the first name (which is
“baker_name”) and last name (which is baker_last_name) . I adjusted the
alignment of the variables in all three datasets so that they are all
consistent and are all arranged by name and series to make it easier to
view and analyze the data. Someone’s name looks weird in bakes_df, so I
use the mutate function to rename the weird names.

``` r
bakers_df = 
  read_csv("./data/gbb_datasets/bakers.csv") %>%
  janitor::clean_names() %>%
  filter(!is.na(baker_name)) %>%
  separate(baker_name, into = c("baker_name", "baker_last_name"), sep = " ", extra = "merge") %>%
  relocate(series, baker_name, baker_last_name) %>%
  arrange(baker_name, series)
bakes_df = 
  read_csv("./data/gbb_datasets/bakes.csv") %>%
  janitor::clean_names() %>%
  rename(baker_name = baker) %>%
  mutate(baker_name = gsub('"', '', baker_name)) %>%
  filter(!is.na(baker_name)) %>%
  arrange(baker_name, series, episode)
results_df = 
  read_csv("./data/gbb_datasets/results.csv", skip = 2) %>%
  janitor::clean_names() %>%
  rename(baker_name = baker) %>%
  filter(!is.na(baker_name)) %>%
  filter(!is.na(result)) %>%
  arrange(baker_name, series, episode)
```

Then check for completeness across the datasets

``` r
missing_bakes1 <- anti_join(bakes_df, bakers_df, by = "baker_name")
missing_bakes2 <- anti_join(bakes_df, results_df, by = "baker_name")
missing_bakes3 <- anti_join(bakers_df, results_df, by = "baker_name")
missing_bakes1 
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
missing_bakes2
```

    ## # A tibble: 8 × 5
    ##   series episode baker_name signature_bake                          show_stopper
    ##    <dbl>   <dbl> <chr>      <chr>                                   <chr>       
    ## 1      2       1 Jo         Chocolate Orange CupcakesOrange and Ca… Chocolate a…
    ## 2      2       2 Jo         Caramelised Onion, Gruyere and Thyme Q… Raspberry a…
    ## 3      2       3 Jo         Stromboli flavored with Mozzarella, Ha… Unknown     
    ## 4      2       4 Jo         Lavender Biscuits                       Blueberry M…
    ## 5      2       5 Jo         Salmon and Asparagus Pie                Apple and R…
    ## 6      2       6 Jo         Rum and Raisin Baked Cheesecake         Limoncello …
    ## 7      2       7 Jo         Raspberry & Strawberry Mousse Cake      Pain Aux Ra…
    ## 8      2       8 Jo         Raspberry and Blueberry Mille Feuille   Mini Victor…

``` r
missing_bakes3
```

    ## # A tibble: 1 × 6
    ##   series baker_name baker_last_name baker_age baker_occupation hometown    
    ##    <dbl> <chr>      <chr>               <dbl> <chr>            <chr>       
    ## 1      2 Jo         Wheatley               41 Housewife        Ongar, Essex

We can find that there are some missing bakers in the results_df.

When I tried to merge three datasets by the bakers’ name, it appeared a
warning, which was “Detected an unexpected many-to-many relationship
between `x` and `y`”. Then I tried to merge the datasets by the bakers’
name, series, and episode at the same time.

So I will merge bakes_df and results_df by the bakers’ name, series, and
episode.

``` r
bakes_results_df = bakes_df %>%
  left_join(results_df, by = c("baker_name", "series", "episode"))
```

Then I merged the new dataset and bakers_df by the bakers’ name, and
series.

``` r
merged_bakers_df =
    left_join(bakes_results_df, bakers_df, by = c("baker_name", "series")) 
```

Finally, organize the final dataset so that variables and observations
are in meaningful orders.

``` r
merged_bakers_df = merged_bakers_df %>%
  relocate(series, episode, baker_name, baker_last_name, 
           baker_age, baker_occupation, hometown, signature_bake, 
           show_stopper, technical, result)
```

Export the final dataset.

``` r
write_csv (merged_bakers_df, "./data/merged_bakers.csv")
```

Briefly description:

The final dataset contains bakers’ basic information and their bakes and
results in the competition. There are 548 rows and 11 columns, with key
variables including series, baker_name, baker_age, signature_bake and so
on.

``` r
star_bakers_df = merged_bakers_df %>%
  filter(series >= 5 & series <= 10, result == "STAR BAKER") %>%
  select(series, episode, baker_name, result) %>%
  arrange(series, episode)
```

``` r
reader_friendly_table = star_bakers_df %>%
  select(-result) %>%
  pivot_wider(names_from = episode, values_from = baker_name, 
              names_prefix = "Episode_")
knitr::kable(reader_friendly_table)
```

| series | Episode_1 | Episode_2 | Episode_3 | Episode_4 | Episode_5 | Episode_6 | Episode_7 | Episode_8 | Episode_9 |
|---:|:---|:---|:---|:---|:---|:---|:---|:---|:---|
| 5 | Nancy | Richard | Luis | Richard | Kate | Chetna | Richard | Richard | Richard |
| 6 | Marie | Ian | Ian | Ian | Nadiya | Mat | Tamal | Nadiya | Nadiya |
| 7 | Jane | Candice | Tom | Benjamina | Candice | Tom | Andrew | Candice | Andrew |
| 8 | Steven | Steven | Julia | Kate | Sophie | Liam | Steven | Stacey | Sophie |
