---
title: "p8105_hw2_yh3822"
output: github_document
date: "2024-10-01"
---

```{r set up, warning=FALSE, message=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```



## Problem 1



```{r, warning=FALSE, message=FALSE}
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%
  mutate(entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE))
```


This dataset describes the information related to each entrance and exit for each subway station in NYC, and it contains `r ncol(nyc_transit_df)` variables, which are line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, and ada. To clean up the data, I first made all the variable names lowercase, then filtered from there the variables I needed to use, removed the unnecessary ones, and finally converted the character variable â€œentry" to a logical variable. The dimension of this dataset is `r nrow(nyc_transit_df)` rows * `r ncol(nyc_transit_df)` columns. I think these data are tidy.


```{r}
distinct_stations = nyc_transit_df %>%
  distinct(station_name, line)
```

There are `r nrow(distinct_stations)` distinct stations.


```{r}
ada_stations = nyc_transit_df %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line)
```

There are `r  nrow(ada_stations)` stations are ADA compliant.


```{r}
no_vending_entry = nyc_transit_df %>%
  filter(vending == "NO" & entry == TRUE) %>%
  distinct(station_name, line)
```

There are `r (nrow(no_vending_entry)/nrow(distinct_stations))*100` percent of station entrances / exits without vending allow entrance.


```{r}
nyc_transit_df = nyc_transit_df %>%
  mutate(across(starts_with("route"), as.character))

nyc_transit_df_tidy = nyc_transit_df %>%
  pivot_longer(cols = starts_with("route"),
               names_to = "route_number",   
               values_to = "route_name",    
               values_drop_na = TRUE)
```


```{r}
a_train_stations = nyc_transit_df_tidy %>%
  filter(route_name == "A") %>%
  distinct(station_name, line)
```

There are `r  nrow(a_train_stations)` distinct stations that served A train.


```{r}
ada_a_train_stations = nyc_transit_df_tidy %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(station_name, line)
```

There are `r  nrow(ada_a_train_stations)` distinct stations that served A train are ADA compliant.


## Problem 2

```{r, warning=FALSE, message=FALSE}
mr_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered, -x15, -x16) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(sports_balls = as.integer(round(sports_balls, 0))) %>%
  mutate(trash_wheel = "Mr. Trash Wheel") %>%
  mutate(year = as.integer(year))
```



```{r, warning=FALSE, message=FALSE}
professor_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(trash_wheel = "Professor Trash Wheel") %>%
  mutate(year = as.integer(year))
```


```{r, warning=FALSE, message=FALSE}
gwynnda_trash_wheel_df = 
  read_xlsx("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) %>%
  janitor::clean_names() %>%
  select(-homes_powered) %>%
  rename(dumpster_number = dumpster) %>%
  filter(!is.na(dumpster_number)) %>%
  mutate(trash_wheel = "Gwynnda Trash Wheel") %>%
  mutate(year = as.integer(year))
```

```{r}
combined_trash_wheel_data <- bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df)
```


This dataset contains information on the various types of trash for the three trash wheels, which are Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel, , reflecting the efforts of these devices to clean up waterways. The dataset contains `r nrow(combined_trash_wheel_data)` observations, with key variables including dumpster_number, month, year, weight_tons, plastic_bottles, polystyrene_containers, and so on. The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trash_wheel_df$weight_tons, na.rm = TRUE)` tons. Additionally, Gwynnda collected `r sum(gwynnda_trash_wheel_df$cigarette_butts[gwynnda_trash_wheel_df$year == 2022 & gwynnda_trash_wheel_df$month == 'June'], na.rm = TRUE)` cigarette butts in June 2022.



## Problem 3


First, import and clean the data.

I found that only the name in the bakers dataset contains both the first and last name, the other two only have the first name, so I turned the name in the bakers dataset into two variables, the first name (which is "baker_name") and last name (which is baker_last_name) . I adjusted the alignment of the variables in all three datasets so that they are all consistent and are all arranged by name and series to make it easier to view and analyze the data. Someone's name looks weird in bakes_df, so I use the mutate function to rename the weird names.

```{r, warning=FALSE, message=FALSE}
bakers_df = 
  read_csv("./data/gbb_datasets/bakers.csv") %>%
  janitor::clean_names() %>%
  filter(!is.na(baker_name)) %>%
  separate(baker_name, into = c("baker_name", "baker_last_name"), sep = " ", extra = "merge") %>%
  relocate(series, baker_name, baker_last_name) %>%
  arrange(baker_name, series)
bakes_df = 
  read_csv("./data/gbb_datasets/bakes.csv") %>%
  janitor::clean_names() %>%
  rename(baker_name = baker) %>%
  mutate(baker_name = gsub('"', '', baker_name)) %>%
  filter(!is.na(baker_name)) %>%
  arrange(baker_name, series, episode)
results_df = 
  read_csv("./data/gbb_datasets/results.csv", skip = 2) %>%
  janitor::clean_names() %>%
  rename(baker_name = baker) %>%
  filter(!is.na(baker_name)) %>%
  filter(!is.na(result)) %>%
  arrange(baker_name, series, episode)
```


Then check for completeness across the datasets

```{r}
missing_bakes1 <- anti_join(bakes_df, bakers_df, by = "baker_name")
missing_bakes2 <- anti_join(bakes_df, results_df, by = "baker_name")
missing_bakes3 <- anti_join(bakers_df, results_df, by = "baker_name")
missing_bakes1 
missing_bakes2
missing_bakes3
```

We can find that there are some missing bakers in the results_df.


When I tried to merge three datasets by the bakers' name, it appeared a warning, which was "Detected an unexpected many-to-many relationship between `x` and `y`". Then I tried to merge the datasets by the bakers' name, series, and episode at the same time.

So I will merge bakes_df and results_df by the bakers' name, series, and episode.

```{r}
bakes_results_df = bakes_df %>%
  left_join(results_df, by = c("baker_name", "series", "episode"))
```

Then I merged the new dataset and bakers_df by the bakers' name, and series.

```{r}
merged_bakers_df =
    left_join(bakes_results_df, bakers_df, by = c("baker_name", "series")) 
```

Finally, organize the final dataset so that variables and observations are in meaningful orders.

```{r}
merged_bakers_df = merged_bakers_df %>%
  relocate(series, episode, baker_name, baker_last_name, 
           baker_age, baker_occupation, hometown, signature_bake, 
           show_stopper, technical, result)
```


Export the final dataset.


```{r}
write_csv (merged_bakers_df, "./data/merged_bakers.csv")
```


Briefly description: 

The final dataset contains bakers' basic information and their bakes and results in the competition. There are `r nrow(merged_bakers_df)` rows and `r ncol(merged_bakers_df)` columns, with key variables including series, baker_name, baker_age, signature_bake and so on.


```{r}
star_bakers_df = merged_bakers_df %>%
  filter(series >= 5 & series <= 10, result == "STAR BAKER") %>%
  select(series, episode, baker_name, result) %>%
  arrange(series, episode)
```



```{r}
reader_friendly_table = star_bakers_df %>%
  select(-result) %>%
  pivot_wider(names_from = episode, values_from = baker_name, 
              names_prefix = "Episode_")
knitr::kable(reader_friendly_table)
```

From the table, we can predict that Richard has the most probability to win in the series 5, Ian and Nadiya are most likely to win in the series 6, Candice is most likely to win in the series 7, Steven is most likely to win in the series 8.


```{r, warning=FALSE, message=FALSE}
viewers_df = 
  read_csv("./data/gbb_datasets/viewers.csv") %>%
  janitor::clean_names() %>%
  mutate_if(is.numeric, ~ round(., 2))
```

To better view the datatset, I change the position of series and episode.

```{r}
viewers_df = viewers_df %>%
  pivot_longer(cols = starts_with("series_"),  
               names_to = "series",
               names_prefix = "series_",
               values_to = "viewers") %>%
  pivot_wider(names_from = episode, 
              values_from = viewers,
              names_prefix = "episode_")
head(viewers_df, n = 10)
```

The average viewership for Season 1 was `r mean(viewers_df %>% filter(series == 1) %>% select(starts_with("episode_")) %>% unlist(), na.rm = TRUE)` million viewers. The average viewership for Season 5 was `r mean(viewers_df %>% filter(series == 5) %>% select(starts_with("episode_")) %>% unlist(), na.rm = TRUE)` million viewers.

